import json
import asyncio
import aio_pika
import logging
from app.constants import RABBITMQ_HOST,QUEUE_NAME,PREFETCH_COUNT
from app.services.scraper.tyba_scraper import TybaScraper

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")


class RabbitMQConsumer:
    """
    Clase as√≠ncrona que encapsula la conexi√≥n a RabbitMQ y el procesamiento de mensajes.
    """
    def __init__(self):
        self.host = RABBITMQ_HOST
        self.queue_name = QUEUE_NAME
        self.prefetch_count=PREFETCH_COUNT
        self.connection = None
        self.channel = None
        self.queue = None

    async def connect(self):
        """
        Establece la conexi√≥n y el canal con RabbitMQ.
        """
        try:
            self.connection = await aio_pika.connect_robust(
                host=self.host,
                port=5672
            )
            self.channel = await self.connection.channel()
            
            # Configurar prefetch para limitar la cantidad de mensajes sin confirmar.
            await self.channel.set_qos(prefetch_count=self.prefetch_count)
            
            # Declarar la cola como durable para que sobreviva a reinicios
            self.queue = await self.channel.declare_queue(self.queue_name, durable=True)
            logging.info(" Conexi√≥n a RabbitMQ establecida.")
        except Exception as e:
            logging.info(f"‚ùå Error conectando a RabbitMQ: {e}")
            raise

    async def callback(self, message: aio_pika.IncomingMessage):
        """
        Funci√≥n que se ejecuta cuando se recibe un mensaje de RabbitMQ.
        """
        try:
            async with message.process():
                # Decodificamos el mensaje recibido
                body = message.body.decode()
                data = json.loads(body)
                process_id = data.get("process_id")
                logging.info(process_id)

                if not process_id:
                    logging.info("‚ö†Ô∏è Mensaje recibido sin process_id, ignorado.")
                    return

                logging.info(f"Recibido process_id: {process_id}, iniciando scraper...")

                # Ejecutar el scraper con el process_id recibido
                scraper = TybaScraper(
                    process_id=process_id,
                    captcha_type="recaptcha_v3"
                )
                await scraper.run()
                logging.info(f"Proceso {process_id} terminado.")

        except Exception as e:
            logging.info(f"‚ùå Error procesando mensaje: {e}")
            
            # Registrar el error antes de rechazar el mensaje
            await message.nack(requeue=False)


    async def start_consuming(self):
        """
        Inicia el proceso de consumo de mensajes de forma as√≠ncrona.
        """
        # Si el canal o la cola no est√°n establecidos, se realiza la conexi√≥n
        if self.channel is None or self.queue is None:
            logging.info("El canal o la cola no est√°n establecidos. Conectando...")
            await self.connect()

        # Configuramos el consumidor pas√°ndole la funci√≥n callback
        await self.queue.consume(self.callback)
        logging.info("üéß Esperando mensajes...")

        # Mantener el proceso en ejecuci√≥n para seguir consumiendo mensajes
        try:
            while True:
                await asyncio.sleep(1)
        except asyncio.CancelledError:
            logging.info("üëã Interrupci√≥n manual. Cerrando conexi√≥n...")
            await self.connection.close()